{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Bharat_AI_SoC_OBB.ipynb"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Bharat AI-SoC | YOLOv8n-obb Pothole Detection \u2192 TFLite INT8\n**FIRST:** Runtime \u2192 Change runtime type \u2192 **T4 GPU** \u2192 Save"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cell 1 \u2014 Check GPU"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import torch, sys\nprint(\"Python :\", sys.version.split()[0])\nprint(\"PyTorch:\", torch.__version__)\nprint(\"CUDA   :\", torch.cuda.is_available())\nif torch.cuda.is_available():\n    print(\"GPU    :\", torch.cuda.get_device_name(0))\n    print(\"\\nGPU OK\")\nelse:\n    print(\"\\nNO GPU \u2014 Runtime > Change runtime type > T4 GPU > Save\")\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cell 2 \u2014 Install packages"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import subprocess, sys\ndef pip(pkg):\n    subprocess.run([sys.executable,\"-m\",\"pip\",\"install\",\"-q\",pkg], check=True)\n\nfor pkg in [\"ultralytics\",\"pyyaml\"]:\n    print(f\"Installing {pkg}...\", end=\" \")\n    pip(pkg)\n    print(\"OK\")\n\nimport ultralytics\nprint(\"\\nultralytics:\", ultralytics.__version__)\nprint(\"All ready!\")\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cell 3 \u2014 Upload and extract dataset\n1. Left sidebar \u2192 Files icon \u2192 Upload\n2. Upload your `data_obb.zip`\n3. Run this cell"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os, subprocess, glob\n\n# Auto-detect uploaded zip name\nZIP_NAME = None\nfor candidate in [\"data_obb.zip\",\"data.zip\",\"pothole_obb.zip\",\"dataset.zip\"]:\n    if os.path.exists(candidate):\n        ZIP_NAME = candidate\n        print(f\"Found zip: {ZIP_NAME}\")\n        break\n\nif not ZIP_NAME:\n    # List all zips in current dir\n    zips = glob.glob(\"*.zip\")\n    if zips:\n        ZIP_NAME = zips[0]\n        print(f\"Found zip: {ZIP_NAME}\")\n    else:\n        raise FileNotFoundError(\n            \"No zip found. Upload your data_obb.zip via the Files panel (left sidebar)\")\n\nprint(f\"Extracting {ZIP_NAME}...\")\nsubprocess.run([\"unzip\",\"-q\",\"-o\", ZIP_NAME,\"-d\",\"obb_dataset\"], check=True)\nDATASET_DIR = \"obb_dataset\"\n\n# Show structure\nprint(\"\\nDataset structure:\")\nfor root, dirs, files in os.walk(DATASET_DIR):\n    level = root.replace(DATASET_DIR,\"\").count(os.sep)\n    if level < 4:\n        nf = len(files)\n        print(\"  \"*level + os.path.basename(root) + f\"/  ({nf} files)\")\n\n# Count images\ntotal = 0\nfor split in [\"train\",\"valid\",\"val\",\"test\"]:\n    p = os.path.join(DATASET_DIR, split, \"images\")\n    if os.path.isdir(p):\n        imgs = (glob.glob(p+\"/*.jpg\")+glob.glob(p+\"/*.png\")+\n                glob.glob(p+\"/*.jpeg\"))\n        if imgs:\n            print(f\"  {split}: {len(imgs)} images\")\n            total += len(imgs)\nprint(f\"  TOTAL: {total} images\")\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cell 4 \u2014 Verify OBB labels and find folders"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os, glob\n\ndef find_dir(base, splits, subdirs):\n    for s in splits:\n        for sub in subdirs:\n            p = os.path.join(base, s, sub)\n            if os.path.isdir(p):\n                files = os.listdir(p)\n                if files:\n                    return os.path.abspath(p)\n    return None\n\nTRAIN_IMGS = find_dir(DATASET_DIR, [\"train\"],                    [\"images\",\"\"])\nVALID_IMGS = find_dir(DATASET_DIR, [\"valid\",\"validation\",\"val\"], [\"images\",\"\"])\nTRAIN_LBLS = find_dir(DATASET_DIR, [\"train\"],                    [\"labels\",\"\"])\nVALID_LBLS = find_dir(DATASET_DIR, [\"valid\",\"validation\",\"val\"], [\"labels\",\"\"])\n\nprint(\"Train images:\", TRAIN_IMGS)\nprint(\"Train labels:\", TRAIN_LBLS)\nprint(\"Valid images:\", VALID_IMGS)\nprint(\"Valid labels:\", VALID_LBLS)\n\n# Check OBB label format (should have 9 values: class + 4 xy pairs)\nif TRAIN_LBLS:\n    sample_txts = glob.glob(TRAIN_LBLS+\"/*.txt\")[:3]\n    print(\"\\nSample label contents:\")\n    for txt in sample_txts:\n        with open(txt) as f:\n            lines = [l.strip() for l in f if l.strip()]\n        if lines:\n            vals = lines[0].split()\n            print(f\"  {os.path.basename(txt)}: {len(vals)} values \u2014 \", end=\"\")\n            if len(vals) == 9:\n                print(\"OBB format (class + 4 xy corners)\")\n            elif len(vals) == 5:\n                print(\"Regular detection format (class + xywh)\")\n            else:\n                print(f\"values: {lines[0][:80]}\")\n\n# Auto-create val split if missing\nif TRAIN_IMGS and not VALID_IMGS:\n    import shutil\n    print(\"\\nNo validation set \u2014 auto-splitting 80/20 from train...\")\n    all_imgs = sorted(glob.glob(TRAIN_IMGS+\"/*.jpg\")+\n                      glob.glob(TRAIN_IMGS+\"/*.png\"))\n    val_imgs = all_imgs[int(len(all_imgs)*0.8):]\n    os.makedirs(DATASET_DIR+\"/val/images\", exist_ok=True)\n    os.makedirs(DATASET_DIR+\"/val/labels\", exist_ok=True)\n    lbl_dir = TRAIN_IMGS.replace(\"images\",\"labels\")\n    for img in val_imgs:\n        shutil.move(img, DATASET_DIR+\"/val/images/\")\n        lbl = os.path.join(lbl_dir,\n              os.path.splitext(os.path.basename(img))[0]+\".txt\")\n        if os.path.exists(lbl):\n            shutil.move(lbl, DATASET_DIR+\"/val/labels/\")\n    VALID_IMGS = os.path.abspath(DATASET_DIR+\"/val/images\")\n    print(f\"Created val set: {len(val_imgs)} images\")\n\nassert TRAIN_IMGS, \"Could not find training images\"\nassert VALID_IMGS, \"Could not find validation images\"\nprint(\"\\nAll folders OK!\")\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cell 5 \u2014 Write data.yaml"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import yaml, os, glob\n\nexisting = glob.glob(DATASET_DIR+\"/*.yaml\")\nnames = [\"pothole\"]\nif existing:\n    try:\n        with open(existing[0]) as f:\n            old = yaml.safe_load(f)\n        if isinstance(old.get(\"names\"), list) and old[\"names\"]:\n            names = old[\"names\"]\n            print(\"Class names:\", names)\n    except:\n        pass\n\nYAML_PATH = os.path.join(DATASET_DIR, \"data.yaml\")\ncfg = {\n    \"path\":  os.path.abspath(DATASET_DIR),\n    \"train\": TRAIN_IMGS,\n    \"val\":   VALID_IMGS,\n    \"nc\":    len(names),\n    \"names\": names,\n}\nwith open(YAML_PATH,\"w\") as f:\n    yaml.dump(cfg, f, default_flow_style=False)\n\nprint(\"data.yaml:\")\nprint(open(YAML_PATH).read())\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cell 6 \u2014 Train YOLOv8n-obb (~15-20 min, do NOT close browser)\n**YOLOv8n-obb** = oriented bounding boxes \u2014 rotated boxes that fit potholes tighter than regular boxes.\nWatch **mAP50** go up."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from ultralytics import YOLO\n\n# yolov8n-obb = nano oriented bounding box model\nmodel = YOLO(\"yolov8n-obb.pt\")\n\nprint(\"Training YOLOv8n-obb on pothole dataset...\")\nprint(\"Epochs: 50 | Image: 320px | Batch: 16\")\nprint(\"Watch: metrics/mAP50(OBB) going up = model learning\")\nprint()\n\nresults = model.train(\n    data       = YAML_PATH,\n    epochs     = 50,\n    imgsz      = 320,\n    batch      = 16,\n    device     = 0,\n    name       = \"pothole_obb\",\n    patience   = 15,\n    optimizer  = \"AdamW\",\n    lr0        = 0.001,\n    augment    = True,\n    mosaic     = 1.0,\n    pretrained = True,\n    verbose    = False,\n    exist_ok   = True,\n)\n\nprint(\"\\nTraining complete!\")\ntry:\n    d = results.results_dict\n    print(f\"OBB mAP50    : {d.get('metrics/mAP50(OBB)',0):.4f}\")\n    print(f\"OBB mAP50-95 : {d.get('metrics/mAP50-95(OBB)',0):.4f}\")\nexcept:\n    print(\"See mAP in training output above\")\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cell 7 \u2014 Export to TFLite INT8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from ultralytics import YOLO\nimport os, glob\n\npts = (glob.glob(\"runs/obb/pothole_obb/weights/best.pt\") +\n       glob.glob(\"runs/obb/pothole_obb*/weights/best.pt\") +\n       glob.glob(\"runs/obb/*/weights/best.pt\"))\n\nassert pts, \"No best.pt found \u2014 did Cell 6 finish?\"\nBEST_PT = sorted(pts)[-1]\nprint(\"Best weights:\", BEST_PT)\n\ntrained = YOLO(BEST_PT)\nprint(\"\\nExporting to TFLite INT8...\")\n\ntrained.export(\n    format = \"tflite\",\n    imgsz  = 320,\n    int8   = True,\n    data   = YAML_PATH,\n    nms    = False,\n)\n\ntflite_files = glob.glob(\"**/*int8*.tflite\", recursive=True)\ntflite_files += [f for f in glob.glob(\"**/*.tflite\", recursive=True)\n                 if f not in tflite_files]\n\nprint(\"\\nTFLite files:\")\nfor f in tflite_files:\n    print(f\"  {f}  ({os.path.getsize(f)/1024/1024:.2f} MB)\")\n\nMODEL_PATH = None\nfor f in tflite_files:\n    if \"int8\" in f.lower():\n        MODEL_PATH = f\n        break\nif not MODEL_PATH and tflite_files:\n    MODEL_PATH = tflite_files[0]\n\nassert MODEL_PATH, \"No .tflite file found\"\nprint(\"\\nUsing:\", MODEL_PATH)\nprint(\"Size  :\", round(os.path.getsize(MODEL_PATH)/1024/1024,2), \"MB\")\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cell 8 \u2014 Inspect output tensors"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import tensorflow as tf\nimport numpy as np\n\ninterp = tf.lite.Interpreter(model_path=MODEL_PATH)\ninterp.allocate_tensors()\n\ninp = interp.get_input_details()\nout = sorted(interp.get_output_details(), key=lambda x: x[\"index\"])\n\nprint(\"INPUT:\")\nfor d in inp:\n    print(f\"  shape={d['shape']}  dtype={d['dtype'].__name__}\")\n\nprint(\"\\nOUTPUTS:\")\nfor d in out:\n    print(f\"  [{d['index']}] shape={d['shape']}  dtype={d['dtype'].__name__}\")\n    print(f\"        name={d['name']}\")\n\ndummy = np.zeros(inp[0][\"shape\"], dtype=inp[0][\"dtype\"])\ninterp.set_tensor(inp[0][\"index\"], dummy)\ninterp.invoke()\nout0 = interp.get_tensor(out[0][\"index\"])\n\nprint(\"\\nOutput[0] shape:\", out0.shape)\nprint(\"\\nMODEL VERIFIED!\")\nprint()\nprint(\"YOLOv8n-obb output format: (1, 6+nc, num_anchors)\")\nprint(\"Channels: [xc, yc, w, h, angle, conf] per anchor\")\nIS_FLOAT_INPUT = inp[0][\"dtype\"] == np.float32\nprint(f\"Float input: {IS_FLOAT_INPUT}\")\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cell 9 \u2014 Download package"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import shutil, os, glob, json\nfrom google.colab import files\n\nos.makedirs(\"rpi5_obb_package\", exist_ok=True)\nshutil.copy(MODEL_PATH, \"rpi5_obb_package/pothole_obb_int8.tflite\")\n\nwith open(\"rpi5_obb_package/labels.txt\",\"w\") as f:\n    f.write(\"pothole\\n\")\n\nout0_shape = list(interp.get_tensor(\n    sorted(interp.get_output_details(),\n           key=lambda x: x[\"index\"])[0][\"index\"]\n).shape)\n\ninfo = {\n    \"model\": \"YOLOv8n-obb INT8 TFLite\",\n    \"input_size\": 320,\n    \"input_float\": IS_FLOAT_INPUT,\n    \"output_shape\": out0_shape,\n    \"classes\": [\"pothole\"],\n    \"format\": \"OBB \u2014 [xc, yc, w, h, angle, conf] per anchor\"\n}\nwith open(\"rpi5_obb_package/model_info.json\",\"w\") as f:\n    json.dump(info, f, indent=2)\n\nprint(\"model_info.json:\")\nprint(json.dumps(info, indent=2))\n\nshutil.make_archive(\"pothole_obb_rpi5\",\"zip\",\"rpi5_obb_package\")\nprint(f\"\\nZip: {os.path.getsize('pothole_obb_rpi5.zip')/1024/1024:.1f} MB\")\nfiles.download(\"pothole_obb_rpi5.zip\")\nprint(\"Done!\")\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cell 10 \u2014 Training summary for report"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os, glob, csv\n\nsize_mb = os.path.getsize(MODEL_PATH)/1024/1024\nbest_map50 = best_map95 = \"N/A\"\n\ncsvs = glob.glob(\"runs/obb/*/results.csv\")\nif csvs:\n    with open(sorted(csvs)[-1]) as f:\n        rows = list(csv.DictReader(f))\n    if rows:\n        cols50 = [k for k in rows[0] if \"mAP50\" in k and \"95\" not in k]\n        cols95 = [k for k in rows[0] if \"mAP50-95\" in k]\n        if cols50:\n            vals = [float(r[cols50[0]]) for r in rows if r[cols50[0]].strip()]\n            best_map50 = f\"{max(vals):.4f}\" if vals else \"N/A\"\n        if cols95:\n            vals = [float(r[cols95[0]]) for r in rows if r[cols95[0]].strip()]\n            best_map95 = f\"{max(vals):.4f}\" if vals else \"N/A\"\n\nprint(\"=\"*60)\nprint(\"  BHARAT AI-SoC \u2014 OBB MODEL TRAINING SUMMARY\")\nprint(\"=\"*60)\nprint(f\"  Architecture     : YOLOv8n-obb (Oriented Bounding Box)\")\nprint(f\"  Task             : Rotated box detection\")\nprint(f\"  Why better       : OBB fits irregular pothole shapes\")\nprint(f\"                     tighter than axis-aligned boxes,\")\nprint(f\"                     reducing false positive area.\")\nprint(f\"  Why ARM-optimized: Depthwise separable convolutions in\")\nprint(f\"                     C2f blocks map to ARM NEON SIMD.\")\nprint(f\"                     INT8 integer ALU = 4x vs FP32.\")\nprint(f\"                     XNNPACK on Cortex-A76 (RPi 5).\")\nprint(f\"  Quantization     : INT8 post-training static\")\nprint(f\"  Model size       : {size_mb:.2f} MB\")\nprint(f\"  Input resolution : 320 x 320 px\")\nprint(f\"  Epochs           : 50 (early stop patience=15)\")\nprint(f\"  Batch size       : 16\")\nprint(f\"  Optimizer        : AdamW  lr0=0.001\")\nprint(f\"  Augmentation     : Mosaic 1.0, flips, HSV\")\nprint(f\"  Pretrained on    : COCO (fine-tuned on pothole data)\")\nprint(f\"  Target hardware  : RPi 5 ARM Cortex-A76 @ 2.4 GHz\")\nprint(f\"  Delegate         : XNNPACK (ARM NEON SIMD)\")\nprint()\nprint(f\"  OBB mAP50        : {best_map50}\")\nprint(f\"  OBB mAP50-95     : {best_map95}\")\nprint(\"=\"*60)\n"
  }
 ]
}